{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Career Path Analysis to be Data Analyst, Data Engineer and Data Scientist in SEEK\n",
    "\n",
    "**Date: 24/03/2022**\n",
    "\n",
    "**Brief Introduction**:\n",
    "\n",
    "This project is to extract, clean, explore and analyze job description data of three popular job titles -- Data Analyst, Data Engineer and Data Scientist, in recent couple of months from the SEEK website. The purpose of this project is to have a quick look at the hottest required technical and soft skills in the job market and help provide career path references for people who would like to be a Data Analyst, Data Engineer, or Data Scientist.\n",
    "\n",
    "**Programming Environment**: Python 3.8 and Jupyter Notebook\n",
    "\n",
    "**Tools used**:\n",
    "- Data Extraction, Data Cleaning and Data Wrangling: PyCharm\n",
    "- Data Wrangling and Database Management: DB Browser for SQLite3 and Elephant DB for PostgreSQL\n",
    "- Data Visualization: Power BI and Tableau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[1.Introduction](#sec_1)\n",
    "\n",
    "- [1.1 Project Objective](#sec_1.1)\n",
    "- [1.2 Target Audience](#sec_1.2)\n",
    "- [1.3 Project Assumption](#sec_1.3)\n",
    "- [1.4 Key Insights](#sec_1.4)\n",
    "\n",
    "[2.Data Wrangling and Methodology](#sec_2)\n",
    "\n",
    "- [2.1 Data Cleaning](#sec_2.1)\n",
    "- [2.2 Dimensional Modeling Method](#sec_2.2)\n",
    "- [2.3 Data Extracting](#sec_2.3)\n",
    "- [2.4 Term Frequency Analysis](#sec_2.4)\n",
    "- [2.5 Documentary Frequency Analysis](#sec_2.5)\n",
    "- [2.6 Requirements & Getting Started](#sec_2.6)\n",
    "\n",
    "[3.Exploratory Data Analysis](#sec_3)\n",
    "\n",
    "- [3.1 Required Skills for Data Analyst](#sec_3.1)\n",
    "- [3.2 Required Skills for Data Engineer](#sec_3.2)\n",
    "- [3.3 Required Skills for Data Scientistg](#sec_3.3)\n",
    "- [3.4 Carrier Path](#sec_3.4)\n",
    "\n",
    "[4.Conclusion](#sec_4)\n",
    "\n",
    "[5.References](#sec_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a class=\"anchor\" id=\"sec_1\"></a>\n",
    "### 1.1 Project Objective <a class=\"anchor\" id=\"sec_1.1\"></a>\n",
    "This project extract, clean, explore and analyze job description data of three popular job titles -- Data Analyst, Data Engineer and Data Scientist, in recent couple of months from SEEK website. This GitHub repo contains all the codes and datasets for this project. The objectives of this project are:\n",
    "\n",
    "- **Clean dirty salary and datetime data, then transform them for analytics**.\n",
    "\n",
    "- **Exploratory data analysis**, e.g. \n",
    "    - ✨find the hottest technical and soft skills for different job titles -- Data Analyst, Data Engineer and Data Scientist.\n",
    "    - ✨analyze the salary differences for different job titles and job types.\n",
    "    - ✨analyze the available positions and required technical skills in different regions.\n",
    "    - ✨analyze the possible relationship between salary range and required technical skills.\n",
    "\n",
    "- **Provide career path references for people who would like to be a Data Analyst, Data Engineer or Data Scientist**.\n",
    "\n",
    "### 1.2 Target Audience <a class=\"anchor\" id=\"sec_1.2\"></a>\n",
    "#### People who would like to be a Data Analyst, Data Engineer, or Data Scientist.\n",
    "### 1.3 Project Assumption <a class=\"anchor\" id=\"sec_1.3\"></a>\n",
    "- Assuming that the SEEK website can represent the current situation and trends of job market in Australia.\n",
    "- Assuming the recruitment data on the SEEK website is accurate.\n",
    "- Assume that people always would like to put the most important information first, for example, the higher the position in the job advertisement. In other words, the earlier the relevant skills appear means that they are more important to the company.\n",
    "\n",
    "### 1.4 Key Insights <a class=\"anchor\" id=\"sec_1.4\"></a>\n",
    "This project extract job description data of three popular job titles -- Data Analyst, Data Engineer and Data Scientist, in recent couple of months from SEEK website. The job locations include eight major cities in Australia – Sydney, Melbourne, Perth, Brisbane, Gold Coast, Adelaide, ACT and Hobart. Among them, there are 2224 job advertisements for Data Analyst, 1180 job advertisements for Data Engineer, and 529 job advertisements for Data Scientist. From the analyzed results, the main conclusions can be summarized as follows: \n",
    "#### Top hottest required skills for Data Analyst: `SQL, Excel, Power BI, Tableau, Python, Data Visualization, Reporting and Communication Skills`\n",
    "#### Top hottest required skills for Data Engineer:`Cloud, SQL, AWS, Python, Azure, Data Pipeline, ETL/ELT, Communication Skills`\n",
    "#### Top hottest required skills for Data Scientist: `Python, Communication Skills, Machine Learning, Data Science, Statistics, Research, Computer Science, SQL`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tData Wrangling and Methodology <a class=\"anchor\" id=\"sec_2\"></a>\n",
    "### 2.1 Data Cleaning - How to Use Regular Expression to Clean the Job Salary and Job Ad Posted Time? <a class=\"anchor\" id=\"sec_2.1\"></a>\n",
    "In this project, we did not analyze the job salary because the data was not plenty enough for the moment. This project focuses more on the analysis of required skills. Moreover, if we have enough recruitment data for several years, we can also analyze the trend of the data job market, for example, how the hottest required skills change over time.\n",
    "#### 2.1.1\tJob Salary Data Cleaning\n",
    "Firstly, we use Regular Expression to extract the salary data and transform them into float numbers from the database.\n",
    "Then, based on different salary range, the job salary can be divided into following three categories: \n",
    "- If salary is lower than 200, it is paid by per hour;\n",
    "- If salary is greater than 200 and lower than 2000, it is paid by per day;\n",
    "- If salary is greater than 2000, it is paid by per annual.\n",
    "\n",
    "In such way, the annual salary can be calculated according to the full-time working hours from Australian government website. There are 251 working days or 2008 working hours per year for a full-time working position.\n",
    "Finally, the data can be converted into a CSV file and needs to be manually checked for errors. \n",
    "\n",
    "#### 2.1.2\tJob Ad Posted Time Data Cleaning\n",
    "The job Ad posted time usually have the following suffixes:\n",
    "- ‘m’ means the job ad was posted minutes ago; \n",
    "- ‘h’ means the job ad was posted hours before; \n",
    "- ‘d’ means the job ad was posted days ago.\n",
    "\n",
    "Based on these suffixes, we can use the Python datetime library to calculate the Universal Time Coordinated date of the job ad posted time.\n",
    "\n",
    "### 2.2\tDimensional Modeling Method – How to Model and Transform the Data into Job Details Fact table and Job Info Dimension Table? <a class=\"anchor\" id=\"sec_2.2\"></a>\n",
    "In this section, the dimensional data modelling technique will be applied to construct the data warehouse which could store and retrieve data quickly for the further analysis. By applying the DDM in this project, the data behavior and domain can be easily understood, and their performance can be optimized.\n",
    "#### 2.2.1\tIdentifying Business Objective\n",
    "Based on the data we have collected, the business objective is to identify the required skills in various job position for the people who would like establish their career in the field of data. Therefore, the key words regarding skills will be extracted and analyzed from the job details.\n",
    "#### 2.2.2\t Identifying Granularity\n",
    "Granularity is the lowest level of information for the tables in the data warehouse. The grain will be used for identifying the level of details for the business problem. Hence, the grain of fact table are job_id, section_id, and line_id which can be used to identify each job details. The grain of dimensional table is job_id which could be used to identify job information.\n",
    "#### 2.2.3\t Identifying Dimensions\n",
    "Dimensions are used for categorizing and describing facts and measures. The job information of each job can be classified as the dimensions in this project. The dimensional table is used for storing the descriptive data and providing the context to the fact creation. In this case, the Job Info Dimensional Table contains all the dimensions of each job such as the job title, job company, job area, etc. \n",
    "#### 2.2.4\t Identifying Facts\n",
    "Since the aim of this project is to investigate the job skills that are required for each position. The fact refers to each job details that is posted as well as the fact table is utilized for storing a collection of measures such as section id, line id, job details, etc.\n",
    "#### 2.2.5\t Building the schema\n",
    "The star schema will be developed based on the following DDM analysis and the Entity Relational Diagram.\n",
    "\n",
    "**Figure 2.1.** Entity Relationship Diagram of Skills Gap Analysis\n",
    "<img src=\"images/01.png\">\n",
    "\n",
    "### 2.3\tData Extracting - How to Filter the Related Recruitment Data for Data Analyst, Data Engineer, Data Scientist from More Than 10,000 Job Descriptions? <a class=\"anchor\" id=\"sec_2.3\"></a>\n",
    "The search algorithm from SEEK website brings up lots of irrelevant job titles, such as business intelligence, accountant, etc. Therefore, before further analysis, we need to filter out the related recruitment data for Data Analyst, Data Engineer, Data Scientist. In this project, we can use SQL LIKE and UNLIKE operator to identify whether if the job title belongs to these three titles or not.\n",
    "\n",
    "Finally, from `13,000` job advertisements, there are `2224` job advertisements for **Data Analyst**, `1180` job advertisements for **Data Engineer**, and `529` job advertisements for **Data Scientist**. \n",
    "\n",
    "### 2.4\tTerm Frequency Analysis – How to Use Word Count to Filter the Key Skills? <a class=\"anchor\" id=\"sec_2.4\"></a>\n",
    "From the downloaded job details data, we can calculate the appeared frequency of each meaningful word(s), including technical and soft skills. Then through the word cloud we can see which technologies are more important than others. We can also use SQL LIKE operator to identify which statements contain these keywords and count the distinct job ad number. According to the above word count and term frequency analysis, we can filter out `46 highly-demand technical and 12 soft skills` in the job market.\n",
    "\n",
    "**The 46 highly-demand skills are as follows**:\n",
    "\n",
    "SQL, Excel, Power BI, Tableau, Python, Cloud, Azure, AWS, GCP, API, Pipeline, Dimension Modelling, ETL/ELT, DevOps, CI/CD, Spark, Java, , Scala, Oracle, Kubernetes, Docker, Apache, Kafka, Linux, Snowflake, Data Warehouse, Data Modelling, Data Visualization, Data Migration, Data Management, Data Integration, Data Platform, Data Architecture, Data Factory, Databricks, Data Science, Machine Learning, Computer Science, Research, Statistic, Mathematics, Quantitative, Algorithm, Deep Learning, Statistical Analysis;\n",
    "\n",
    "**The 12 highly-demand soft skills are as follows**:\n",
    "\n",
    "Communication Skill, Reporting, Stakeholder, Agile, Project Management, Business Intelligence, Decision Making, Interpersonal, Time Management, Troubleshoot, Tertiary Qualification, PhD\n",
    "\n",
    "### 2.5\tDocumentary Frequency Analysis – How to Identify the Importance of Key Skills?<a class=\"anchor\" id=\"sec_2.5\"></a>\n",
    "In this section, to further illustrate which skills are more important, we select 8 skills most in demand for the following documentary frequency analysis.\n",
    "\n",
    "As elaborated in the assumption chapter, people always would like to put the most important information first, for example, the higher the position in the job advertisement. We can analyze the average appeared line number of these important skills. We can also categorize their first occurrence line numbers into three range: 1 ~ 3, 4 ~ 5 and 6+. From these specific analyses, we can distinguish the order of importance of these skills. The top hottest required skills for Data Analyst, Data Engineer and Data Scientist are as follows:\n",
    "\n",
    "**Data Analyst**: `SQL, Excel, Power BI, Tableau, Python, Visualization, Reporting and Communication Skills`; \n",
    "\n",
    "**Data Engineer**: `Cloud, SQL, AWS, Python, Azure, Data Pipeline, ETL/ELT, Communication Skills`; \n",
    "\n",
    "**Data Scientist**: `Python, Communication Skills, Machine Learning, Computer Science, Data Science, Research, SQL, Statistics`.\n",
    "\n",
    "**Tools used in the project**:\n",
    "\n",
    "- Programming Environment: Python 3.8 and Jupyter Notebook\n",
    "- Data Extraction, Data Cleaning and Data Wrangling: PyCharm\n",
    "- Data Wrangling and Database Management: DB Browser for SQLite3 and Elephant DB for PostgreSQL\n",
    "- Data Visualization: Power BI and Tableau\n",
    "\n",
    "### 2.6\tRequirements & Getting Started <a class=\"anchor\" id=\"sec_2.6\"></a>\n",
    "**Dependencies include**:\n",
    "- json\n",
    "- glob\n",
    "- sqlite3\n",
    "- re\n",
    "- pandas \n",
    "- typing\n",
    "- nltk.corpus\n",
    "- datetime\n",
    "- os\n",
    "- requests\n",
    "- urllib.parse\n",
    "- bs4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis<a class=\"anchor\" id=\"sec_3\"></a>\n",
    "\n",
    "In this part, average line number of key skills in each job title will be explored to discover skill importance, where the top skills mean more significant. Moreover, job count will be conducted for each key skill in three job titles, which aims to examine hottest skills in each job titles.\n",
    "### 3.1\tRequired Skills for Data Analyst <a class=\"anchor\" id=\"sec_3.1\"></a>\n",
    "#### 3.1.1\tTerm Frequency and Word Cloud for Data Analyst\n",
    "From the downloaded job details, we can calculate the appeared frequency of each meaningful word(s), including technical and soft skills. Then we can draw Word Cloud as shown Figure 3.1.\n",
    "\n",
    "**Figure 3.1**. Word Cloud for Data Analyst.\n",
    "<img src=\"images/02.png\">\n",
    "#### 3.1.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Analyst\n",
    "Based on the word cloud shown above, we can see which technologies are more important than others. Then we use SQL LIKE operator to identify which statements contain these keywords and count the distinct total number of job ads. In such ways, we can obtain the percentage of JDs required the technical and soft skills in total JDs, as shown in Figure 3.2 and Figure 3.3. From the figures, we can conclude that the top 8 hottest required skills for Data Analyst are **`SQL, Excel, Power BI, Tableau, Python, Data Visualization, Reporting and Communication Skills`**. The JDs required these skills account for nearly or more than 20 percent of the total JDs.\n",
    "\n",
    "The other important technical skills are `Statistic, Data Warehouse, Cloud, Research, Data Modeling, Deep Learning, Azure, ETL/ELT, Computer Science, AWS`, etc. These skills are also quite important to become a professional Data Analyst. We can tell that people need to have excellent Data Visualization and Reporting skills to be Data Analyst than Data Scientist and Data Engineer.\n",
    "\n",
    "**Figure 3.2**. Technical Skills Required to be a Data Analyst.\n",
    "<img src=\"images/03.png\">\n",
    "<img src=\"images/04.png\">\n",
    "\n",
    "**Figure 3.3**. Soft Skills Required to be a Data Analyst.\n",
    "<img src=\"images/05.png\">\n",
    "#### 3.1.3\tRanked Line in the Job Description of Technical Skills \n",
    "In order to illustrate further of our conclusions, we assume that people always would like to put the most important information first, for example, the higher the position in the job advertisement. Then we analyze the average appeared line number of these important skills. We categorize their first occurrence line numbers into three range: 1 ~ 3, 4 ~ 5 and 6+, as shown in Figure 3.4 and Figure 3.5. \n",
    "\n",
    "From the figures, we can see that there are **`783 times that SQL appears in the first to third lines`**, 219 times that SQL appears in the fourth and fifth lines, and 131 times that appears in other lines. There are **`510 times that Excel appears in the first to third lines`**, 272 times that appears in the fourth and fifth lines, and 252 times that appears in other lines. The more times they appear in the front lines, means that they are more important than other skills. From these specific analyses, we can distinguish the order of importance of these skills. \n",
    "\n",
    "**Data Analyst: SQL, Excel, Power BI, Tableau, Python, Data Visualization, Reporting and Communication Skills.**\n",
    "\n",
    "**Figure 3.4**.  Ranked Line in the Job Description of Technical Skills for Data Analyst.\n",
    "<img src=\"images/06.png\">\n",
    "<img src=\"images/07.png\">\n",
    "\n",
    "**Figure 3.5**. Ranked Line in the Job Description of Soft Skills for Data Analyst.\n",
    "<img src=\"images/08.png\">\n",
    "#### 3.1.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
    "We can also calculate the average ranked line in the job description of these skills, as shown in Figure 3.6. \n",
    "\n",
    "**Figure 3.6**.  Average Ranked Line in the Job Description of Technical Skills\n",
    "<img src=\"images/09.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2\tRequired Skills for Data Engineer<a class=\"anchor\" id=\"sec_3.2\"></a>\n",
    "#### 3.2.1\tTerm Frequency and Word Cloud for Data Engineer\n",
    "By similar analysis method, we can calculate the appeared frequency of each meaningful word(s) in the Data Engineer JDs. Then we can draw Word Cloud as shown Figure 3.7.\n",
    "\n",
    "**Figure 3.7**. Word Cloud for Data Engineer\n",
    "<img src=\"images/10.png\">\n",
    "#### 3.2.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Engineer\n",
    "Based on the word cloud shown above, we can see which technologies are more important than others. Then we use SQL LIKE operator to identify which statements contain these keywords and count the distinct total number of job ads. In such ways, we can obtain the percentage of JDs required the technical and soft skills in total Data Engineer JDs, as shown in Figure 3.8 and Figure 3.9. \n",
    "\n",
    "From the figures, we can conclude that the top 8 hottest required skills for Data Engineer are **`Cloud, SQL, AWS, Python, Azure, Data Pipeline, ETL/ELT, Communication Skills`**. The JDs required these skills account for nearly or more than 30 percent of the total JDs. The other also important technical skills are `Data Warehouse, Excel, DevOps, Scala, CI/CD, Data Modeling, Deep Learning, Data Architecture, Spark, Java`, etc. These skills are also quite important to become a professional Data Engineer. We can tell that people need to master the most skills to be Data Engineer than Data Analyst and Data Scientists.\n",
    "\n",
    "**Figure 3.8**. Technical Skills Required to be a Data Engineer\n",
    "<img src=\"images/11.png\">\n",
    "<img src=\"images/12.png\">\n",
    "**Figure 3.9**. Soft Skills Required to be a Data Engineer\n",
    "<img src=\"images/13.png\">\n",
    "#### 3.2.3\tRanked Line in the Job Description of Technical Skills \n",
    "Then we analyze the average appeared line number of these important skills. We categorize their first occurrence line numbers into three range: 1 ~ 3, 4 ~ 5 and 6+, as shown in Figure 3.10 and Figure 3.11. \n",
    "\n",
    "From the figures, we can see that there are `501 times that Cloud appears in the first to third lines`, 79 times that appears in the fourth and fifth lines, and 66 times that appears in other lines. In such way, we can distinguish the order of importance of these skills. The more times they appear in the front lines, means that they are more important than other skills. From Figure 3.100, we can conclude that the top demand skills are **Cloud, SQL, AWS, Python, Azure, Data Pipeline, ETL/ELT, Communication Skills**. The other important technical skills are `Excel, DevOps, Scala, CI/CD, Data Modeling, Data Architecture, Data Warehouse, Spark, Data Ingestion, API, Java`, etc.\n",
    "\n",
    "**Figure 3.10**.  Ranked Line in the Job Description of Technical Skills for Data Engineer\n",
    "<img src=\"images/14.png\">\n",
    "<img src=\"images/15.png\">\n",
    "**Figure 3.11**. Ranked Line in the Job Description of Soft Skills for Data Engineer\n",
    "<img src=\"images/16.png\">\n",
    "#### 3.2.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
    "Then we can calculate the average ranked line in the job description of these skills, as shown in Figure 3.12. \n",
    "\n",
    "**Figure 3.12**. Average Ranked Line in the Job Description of Technical Skills\n",
    "<img src=\"images/17.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3\tRequired Skills for Data Scientist<a class=\"anchor\" id=\"sec_3.3\"></a>\n",
    "#### 3.3.1\tTerm Frequency and Word Cloud for Data Scientist\n",
    "By similar analysis method, we can calculate the appeared frequency of each meaningful word(s) in the Data Scientist JDs. Then we can draw Word Cloud as shown Figure 3.13.\n",
    "\n",
    "**Figure 3.13**.  Word Cloud for Data Scientist\n",
    "<img src=\"images/18.png\">\n",
    "\n",
    "#### 3.3.2\tDocumentary Frequency Analysis and Technical Skills Required to be a Data Scientist\n",
    "Based on the word cloud shown above and using SQL LIKE operator to identify which statements contain these keywords, we can count the distinct total number of job ads. In such ways, we can obtain the percentage of JDs required the technical and soft skills in total Data Scientist JDs, as shown in Figure 3.14 and Figure 3.15. \n",
    "\n",
    "From the figures, we can conclude that the top 8 hottest required skills for Data Engineer are `Python, Communication Skills, Machine Learning, Data Science, Statistics, Research, Computer Science, SQL`. The JDs required these skills account for nearly or more than 30 percent of the total JDs. The other also important technical skills are `Excel, Mathematics, Cloud, Algorithms, Quantitative, Data Modeling, Deep Learning, AWS, Spark`, etc. These skills are also quite important to become a professional Data Scientist. We can tell that people better to have strong understanding of the machine learning and mathematical foundations to be Data Scientist than Data Analyst and Data Engineer.\n",
    "\n",
    "**Figure 3.14**. Technical Skills Required to be a Data Scientist\n",
    "<img src=\"images/19.png\">\n",
    "<img src=\"images/20.png\">\n",
    "**Figure 3.15**. Soft Skills Required to be a Data Scientist\n",
    "<img src=\"images/21.png\">\n",
    "\n",
    "#### 3.3.3\tRanked Line in the Job Description of Technical Skills \n",
    "Then we analyze the average appeared line number of these important skills. We categorize their first occurrence line numbers into three range: 1~3, 4~5 and 6+, as shown in Figure 3.16 and Figure 3.17. \n",
    "\n",
    "From the figures, we can see that there are `156 times that Python appears in the first to third lines`, 45 times that appears in the fourth and fifth lines, and 29 times that appears in other lines. In such way, we can distinguish the order of importance of these skills. The more times they appear in the front lines, means that they are more important than other skills. From Figure 3.14, we can conclude that the top demand skills are `Python, Communication Skills, Machine Learning, Data Science, Statistics, Research, SQL, Computer Science`. The other important technical skills are `Excel, Mathematics, Cloud, Algorithms, Quantitative, Data Modeling, AWS, Spark`, etc.\n",
    "\n",
    "**Figure 3.16**.  Ranked Line in the Job Description of Technical Skills for Data Scientist\n",
    "<img src=\"images/22.png\">\n",
    "<img src=\"images/23.png\">\n",
    "**Figure 3.17**. Ranked Line in the Job Description of Soft Skills for Data Scientist\n",
    "<img src=\"images/24.png\">\n",
    "\n",
    "#### 3.3.4\tAverage Ranked Line in the Job Description of Technical Skills \n",
    "We can also calculate the average ranked line in the job description of these skills, as shown in Figure 3.18.\n",
    "\n",
    "**Figure 3.18**.  Average Ranked Line in the Job Description of Technical Skills\n",
    "<img src=\"images/25.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4\tCarrier Path<a class=\"anchor\" id=\"sec_3.4\"></a>\n",
    "#### 3.4.1\tThe Necessary Skills to Become a Data Analyst, Data Engineer and Data Scientist\n",
    "From the analysis elaborated above, we can conclude that the hottest required skills for Data Analyst are **SQL, Excel, Power BI, Tableau, Python, Data Visualization, Reporting and Communication Skills**; the hottest required skills for Data Engineer are **Cloud, SQL, AWS, Python, Azure, Data Pipeline, ETL/ELT, Communication Skills**; the top hottest required skills for Data Scientist are **Python, Communication Skills, Machine Learning, Data Science, Statistics, Research, Computer Science, SQL**.\n",
    "Then we can draw the dashboard for these necessary skills to be a Data Analyst, Data Engineer, and Data Scientist, as shown in Figure 3.19 – 3.21 .\n",
    "\n",
    "**Figure 3.19**.  Dashboard for the Necessary Skills to be a Data Analyst\n",
    "<img src=\"images/26.png\">\n",
    "\n",
    "**Figure 3.20**.  Dashboard for the Necessary Skills to be a Data Engineer\n",
    "<img src=\"images/27.png\">\n",
    "\n",
    "**Figure 3.21**.  Dashboard for Necessary Skills to be a Data Scientist\n",
    "<img src=\"images/28.png\">\n",
    "\n",
    "#### 3.4.2\tAdditional Skills while Switching Between Data Analyst, Data Engineer and Data Scientist\n",
    "From the following schematic diagram of the career path between Data Analyst, Data Engineer and Data Scientist, we can tell that SQL, Python and communication skills are mandatory skills in the big data field.\n",
    "\n",
    "If people want to change carrier from Data Analyst to Data Engineer, they must obtain **Cloud experience, such as AWS, Azure**. They will also need to obtain other necessary skills and experience such as **ETL/ELT, Spark, Data Pipeline, DevOps**.\n",
    "\n",
    "If people who are Data Analysts would like to be Data Scientists, they are better to have **research or algorithms experience** and strong knowledge for the following fields, such as **Machine Learning, Data Science, Statistic, Mathematics**.\n",
    "\n",
    "If people would like to change career from Data Engineer and Data Scientist to Data Analyst, they not only need to obtain **strong hands-on experience on SQL and Python**, but also need to improve **Data Visualization skills, i.e.  Power BI, Tableau, Excel, and Reporting / story telling skills**. \n",
    "\n",
    "**Figure 3.22**. Schematic Diagram of the Career Path between Data Analyst, Data Engineer and Data Scientist\n",
    "<img src=\"images/29.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\tConclusion<a class=\"anchor\" id=\"sec_4\"></a>\n",
    "From the analysis between Data Analyst, Data Engineer and Data Scientist elaborated above, we can conclude that **SQL, Python and communication skills are mandatory skills in the big data field**. However, these three job titles also have their own special technical tendencies depending on different responsibilities:\n",
    "\n",
    "To be **Data Analysts requires strong data visualization, reporting skills and domain knowledge** because they need to use data to communicate and help companies make business decisions.\n",
    "\n",
    "To be **Data Engineers needs to master more technical skills** as their job is to build the data pipeline and optimize the systems to allow data analysts and data scientist to perform their work. \n",
    "\n",
    "While **Data Scientists** use **statistics and machine learning algorithms** to make predictions, it requires excellent mathematics, statistics knowledge, and research experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tReferences<a class=\"anchor\" id=\"sec_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style id=hide>div.input{display:none;}</style>\n",
       "<button type=\"button\"onclick=\"var myStyle = document.getElementById('hide').sheet;\n",
       "myStyle.insertRule('div.input{display:inherit !important;}', 0);\">Show the code</button>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run me to hide code cells\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(r\"\"\"<style id=hide>div.input{display:none;}</style>\n",
    "<button type=\"button\"onclick=\"var myStyle = document.getElementById('hide').sheet;\n",
    "myStyle.insertRule('div.input{display:inherit !important;}', 0);\">Show the code</button>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "\n",
       "import pandas as pd\n",
       "import re\n",
       "\n",
       "\n",
       "job_details = pd.read_csv('seek_data_analyst_job_extra_info.csv')\n",
       "\n",
       "# job_salary data cleaning\n",
       "salary_up = []\n",
       "salary_down = []\n",
       "for i in job_details['job_salary']:\n",
       "    # use Regular Expression to extract the salary data and transform them into float numbers from the database.\n",
       "    salary = re.findall(r'[\\$-]([\\d, kK]+)', str(i))\n",
       "    salary_new1 = [s.replace(',', '') for s in salary]\n",
       "    salary_new2 = [s.replace('k', '000') for s in salary_new1]\n",
       "    salary_new3 = [s.replace('K', '000') for s in salary_new2]\n",
       "    salary_new4 = [s.replace(' ', '') for s in salary_new3]\n",
       "    salary_new5 = [s for s in salary_new4 if s != '']\n",
       "\n",
       "    if len(salary_new5) == 1 and salary_new5[0].isdigit():\n",
       "        salary_down.append(float(salary_new5[0]))\n",
       "        salary_up.append('')\n",
       "    elif len(salary_new5) == 2:\n",
       "        salary_down.append(float(salary_new5[0]))\n",
       "        salary_up.append(float(salary_new5[1]))\n",
       "    else:\n",
       "        salary_down.append('')\n",
       "        salary_up.append('')\n",
       "\n",
       "job_details['job_salary_down'] = salary_down\n",
       "job_details['job_salary_up'] = salary_up\n",
       "\n",
       "# based on different salary range, the job salary can be divided into following three categories: \n",
       "# If salary is lower than 200, it is paid by per hour;\n",
       "# If salary is greater than 200 and lower than 2000, it is paid by per day;\n",
       "# If salary is greater than 2000, it is paid by per annual.\n",
       "# In such way, the annual salary can be calculated according to the full-time working hours from Australian government website. \n",
       "# There are 251 working days or 2008 working hours per year for a full-time working position.\n",
       "\n",
       "job_details['annual_salary_down'] = job_details['job_salary_down']\n",
       "\n",
       "job_details.annual_salary_down[(200 > job_details['job_salary_down'])] = job_details['job_salary_down'] * 2008\n",
       "job_details.annual_salary_down[(200 < job_details['job_salary_down'])\n",
       "                          & (job_details['job_salary_down'] < 2000)] = job_details['job_salary_down'] * 251\n",
       "\n",
       "\n",
       "job_details['annual_salary_up'] = job_details['job_salary_up']\n",
       "\n",
       "job_details.annual_salary_up[(200 > job_details['job_salary_down'])] = job_details['job_salary_up'] * 2008\n",
       "job_details.annual_salary_up[(200 < job_details['job_salary_down'])\n",
       "                          & (job_details['job_salary_down'] < 2000)] = job_details['job_salary_up'] * 251\n",
       "\n",
       "# Finally, the data can be converted into a CSV file and needs to be manually checked for errors. \n",
       "job_details.to_csv('seek_data_analyst_job_extra_info_cleaned.csv', index=False)\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this salary data cleaning is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "job_details = pd.read_csv('seek_data_analyst_job_extra_info.csv')\n",
    "\n",
    "# job_salary data cleaning\n",
    "salary_up = []\n",
    "salary_down = []\n",
    "for i in job_details['job_salary']:\n",
    "    # use Regular Expression to extract the salary data and transform them into float numbers from the database.\n",
    "    salary = re.findall(r'[\\$-]([\\d, kK]+)', str(i))\n",
    "    salary_new1 = [s.replace(',', '') for s in salary]\n",
    "    salary_new2 = [s.replace('k', '000') for s in salary_new1]\n",
    "    salary_new3 = [s.replace('K', '000') for s in salary_new2]\n",
    "    salary_new4 = [s.replace(' ', '') for s in salary_new3]\n",
    "    salary_new5 = [s for s in salary_new4 if s != '']\n",
    "\n",
    "    if len(salary_new5) == 1 and salary_new5[0].isdigit():\n",
    "        salary_down.append(float(salary_new5[0]))\n",
    "        salary_up.append('')\n",
    "    elif len(salary_new5) == 2:\n",
    "        salary_down.append(float(salary_new5[0]))\n",
    "        salary_up.append(float(salary_new5[1]))\n",
    "    else:\n",
    "        salary_down.append('')\n",
    "        salary_up.append('')\n",
    "\n",
    "job_details['job_salary_down'] = salary_down\n",
    "job_details['job_salary_up'] = salary_up\n",
    "\n",
    "# based on different salary range, the job salary can be divided into following three categories: \n",
    "# If salary is lower than 200, it is paid by per hour;\n",
    "# If salary is greater than 200 and lower than 2000, it is paid by per day;\n",
    "# If salary is greater than 2000, it is paid by per annual.\n",
    "# In such way, the annual salary can be calculated according to the full-time working hours from Australian government website. \n",
    "# There are 251 working days or 2008 working hours per year for a full-time working position.\n",
    "\n",
    "job_details['annual_salary_down'] = job_details['job_salary_down']\n",
    "\n",
    "job_details.annual_salary_down[(200 > job_details['job_salary_down'])] = job_details['job_salary_down'] * 2008\n",
    "job_details.annual_salary_down[(200 < job_details['job_salary_down'])\n",
    "                          & (job_details['job_salary_down'] < 2000)] = job_details['job_salary_down'] * 251\n",
    "\n",
    "\n",
    "job_details['annual_salary_up'] = job_details['job_salary_up']\n",
    "\n",
    "job_details.annual_salary_up[(200 > job_details['job_salary_down'])] = job_details['job_salary_up'] * 2008\n",
    "job_details.annual_salary_up[(200 < job_details['job_salary_down'])\n",
    "                          & (job_details['job_salary_down'] < 2000)] = job_details['job_salary_up'] * 251\n",
    "\n",
    "# Finally, the data can be converted into a CSV file and needs to be manually checked for errors. \n",
    "job_details.to_csv('seek_data_analyst_job_extra_info_cleaned.csv', index=False)\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this salary data cleaning is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "from datetime import datetime, timedelta\n",
       "import pandas as pd\n",
       "import sqlite3\n",
       "\n",
       "\n",
       "def getdate(days_ago: int, hours_ago: int, minutes_ago: int):\n",
       "    time_now = datetime.utcnow()\n",
       "    time_diff = timedelta(days=days_ago, hours=hours_ago, minutes=minutes_ago)\n",
       "    return (time_now - time_diff).strftime('%Y-%m-%d %H:%M:%S')\n",
       "\n",
       "\n",
       "job_details = pd.read_csv('seek_data_analyst_job_extra_info_cleaned.csv')\n",
       "job_posted_time = []\n",
       "\n",
       "for dates in job_details['job_listing_date']:\n",
       "    if 'd' in str(dates):\n",
       "        days_ago = int(dates.split('d')[0])\n",
       "        job_posted_time.append(getdate(days_ago, 0, 0))\n",
       "    elif 'h' in str(dates):\n",
       "        hours_ago = int(dates.split('h')[0])\n",
       "        job_posted_time.append(getdate(0, hours_ago, 0))\n",
       "    elif 'm' in str(dates):\n",
       "        minutes_ago = int(dates.split('m')[0])\n",
       "        job_posted_time.append(getdate(0, 0, minutes_ago))\n",
       "    else:\n",
       "        job_posted_time.append('')\n",
       "\n",
       "print(job_posted_time)\n",
       "job_details['job_posted_time'] = job_posted_time\n",
       "job_details.to_csv('seek_data_analyst_job_extra_info_cleaned2.csv', index=False)\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for the datatime data cleaning is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def getdate(days_ago: int, hours_ago: int, minutes_ago: int):\n",
    "    time_now = datetime.utcnow()\n",
    "    time_diff = timedelta(days=days_ago, hours=hours_ago, minutes=minutes_ago)\n",
    "    return (time_now - time_diff).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "job_details = pd.read_csv('seek_data_analyst_job_extra_info_cleaned.csv')\n",
    "job_posted_time = []\n",
    "\n",
    "for dates in job_details['job_listing_date']:\n",
    "    if 'd' in str(dates):\n",
    "        days_ago = int(dates.split('d')[0])\n",
    "        job_posted_time.append(getdate(days_ago, 0, 0))\n",
    "    elif 'h' in str(dates):\n",
    "        hours_ago = int(dates.split('h')[0])\n",
    "        job_posted_time.append(getdate(0, hours_ago, 0))\n",
    "    elif 'm' in str(dates):\n",
    "        minutes_ago = int(dates.split('m')[0])\n",
    "        job_posted_time.append(getdate(0, 0, minutes_ago))\n",
    "    else:\n",
    "        job_posted_time.append('')\n",
    "\n",
    "print(job_posted_time)\n",
    "job_details['job_posted_time'] = job_posted_time\n",
    "job_details.to_csv('seek_data_analyst_job_extra_info_cleaned2.csv', index=False)\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for the datatime data cleaning is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "import re\n",
       "import pandas as pd\n",
       "from typing import Tuple, List, Iterable, Any\n",
       "import nltk\n",
       "from nltk.corpus import stopwords\n",
       "\n",
       "\n",
       "keywords = ['SQL', 'Excel', 'PowerBI', 'Tableau', 'Python', 'Cloud'\n",
       "        , 'Azure', 'AWS', 'GCP', 'API', 'Pipeline', 'Dimension Modelling', 'ETL', 'ELT'\n",
       "        , 'DevOps', 'CI CD', 'Spark', 'Java', 'Scala', 'Oracle', 'Kubernetes', 'Docker'\n",
       "        , 'Apache', 'Kafka', 'Linux', 'Snowflake', 'Data Warehouse'\n",
       "        , 'Data Modelling', 'Data Visualisation', 'Data Migration', 'Data Management'\n",
       "        , 'Data Integration', 'Data Platform', 'Data Architecture', 'Data Factory', 'Databricks', 'Data Science'\n",
       "        , 'Machine Learning', 'Computer Science', 'Research', 'Statistic', 'Mathematics'\n",
       "        , 'Quantitative', 'Algorithm', 'Deep Learning', 'Statistical Analysis'\n",
       "        , 'Communication Skill', 'Stakeholder', 'Reporting', 'Agile'\n",
       "        , 'Project Management', 'Business Intelligence', 'Decision Making', 'Interpersonal'\n",
       "        , 'Time Management', 'Troubleshoot', 'Tertiary Qualification', 'PhD']\n",
       "\n",
       "\n",
       "# nltk.download('stopwords')\n",
       "def ngram(l: Iterable[Any], gram: int) -> List[Any]:\n",
       "    l = list(l)\n",
       "    return [l[i: i + gram] for i in range(len(l) - gram + 1)]\n",
       "\n",
       "\n",
       "def get_words(line: str, gram: int) -> List[str]:\n",
       "    words = re.findall(r'[a-zA-Z]+', line.lower())\n",
       "    if gram == 1:\n",
       "        stop_words = stopwords.words('english')\n",
       "        words = [word for word in words if word not in stop_words]\n",
       "    else:\n",
       "        words = [' '.join(word) for word in ngram(words, gram)]\n",
       "    return words\n",
       "\n",
       "\n",
       "# 每次输入一句string，统计单词或词组出现的次数\n",
       "def word_count(stats: dict, sentence: str, gram: int) -> dict:\n",
       "    if isinstance(sentence, str):\n",
       "        # matched = re.findall(r'[a-zA-Z]+', sentence.lower())\n",
       "        # without_stop_words = [word for word in matched if word not in stop_words]\n",
       "        for word in get_words(sentence, gram):\n",
       "            if word in stats:\n",
       "                stats[word] += 1\n",
       "            else:\n",
       "                stats[word] = 1\n",
       "    return stats\n",
       "    \n",
       "\n",
       "def sorted_word_count(d: dict) -> Tuple:\n",
       "    return sorted(list(d.items()), key=lambda x: x[-1], reverse=True)\n",
       "\n",
       "\n",
       "# read the job details file\n",
       "wc = {}\n",
       "job_uls = pd.read_csv('data_scientist/seek_data_scientist_job_details_filtered.csv')\n",
       "\n",
       "for ul in job_uls['detail']:\n",
       "    wc = word_count(wc, ul, gram=1)\n",
       "\n",
       "for i in sorted_word_count(wc):\n",
       "    print(i)\n",
       "    \n",
       "df = pd.DataFrame(sorted_word_count(wc))\n",
       "\n",
       "df.to_csv('seek_data_scientist_gram_1.csv', index=False)\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for the word count - Term Frequency Analysis is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Iterable, Any\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "keywords = ['SQL', 'Excel', 'PowerBI', 'Tableau', 'Python', 'Cloud'\n",
    "        , 'Azure', 'AWS', 'GCP', 'API', 'Pipeline', 'Dimension Modelling', 'ETL', 'ELT'\n",
    "        , 'DevOps', 'CI CD', 'Spark', 'Java', 'Scala', 'Oracle', 'Kubernetes', 'Docker'\n",
    "        , 'Apache', 'Kafka', 'Linux', 'Snowflake', 'Data Warehouse'\n",
    "        , 'Data Modelling', 'Data Visualisation', 'Data Migration', 'Data Management'\n",
    "        , 'Data Integration', 'Data Platform', 'Data Architecture', 'Data Factory', 'Databricks', 'Data Science'\n",
    "        , 'Machine Learning', 'Computer Science', 'Research', 'Statistic', 'Mathematics'\n",
    "        , 'Quantitative', 'Algorithm', 'Deep Learning', 'Statistical Analysis'\n",
    "        , 'Communication Skill', 'Stakeholder', 'Reporting', 'Agile'\n",
    "        , 'Project Management', 'Business Intelligence', 'Decision Making', 'Interpersonal'\n",
    "        , 'Time Management', 'Troubleshoot', 'Tertiary Qualification', 'PhD']\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "def ngram(l: Iterable[Any], gram: int) -> List[Any]:\n",
    "    l = list(l)\n",
    "    return [l[i: i + gram] for i in range(len(l) - gram + 1)]\n",
    "\n",
    "\n",
    "def get_words(line: str, gram: int) -> List[str]:\n",
    "    words = re.findall(r'[a-zA-Z]+', line.lower())\n",
    "    if gram == 1:\n",
    "        stop_words = stopwords.words('english')\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    else:\n",
    "        words = [' '.join(word) for word in ngram(words, gram)]\n",
    "    return words\n",
    "\n",
    "\n",
    "# 每次输入一句string，统计单词或词组出现的次数\n",
    "def word_count(stats: dict, sentence: str, gram: int) -> dict:\n",
    "    if isinstance(sentence, str):\n",
    "        # matched = re.findall(r'[a-zA-Z]+', sentence.lower())\n",
    "        # without_stop_words = [word for word in matched if word not in stop_words]\n",
    "        for word in get_words(sentence, gram):\n",
    "            if word in stats:\n",
    "                stats[word] += 1\n",
    "            else:\n",
    "                stats[word] = 1\n",
    "    return stats\n",
    "    \n",
    "\n",
    "def sorted_word_count(d: dict) -> Tuple:\n",
    "    return sorted(list(d.items()), key=lambda x: x[-1], reverse=True)\n",
    "\n",
    "\n",
    "# read the job details file\n",
    "wc = {}\n",
    "job_uls = pd.read_csv('data_scientist/seek_data_scientist_job_details_filtered.csv')\n",
    "\n",
    "for ul in job_uls['detail']:\n",
    "    wc = word_count(wc, ul, gram=1)\n",
    "\n",
    "for i in sorted_word_count(wc):\n",
    "    print(i)\n",
    "    \n",
    "df = pd.DataFrame(sorted_word_count(wc))\n",
    "\n",
    "df.to_csv('seek_data_scientist_gram_1.csv', index=False)\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for the word count - Term Frequency Analysis is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "\n",
       "import pandas as pd\n",
       "from typing import Tuple, List, Iterable, Any\n",
       "\n",
       "\n",
       "def filtered_keywords(sentence: str) -> list:\n",
       "    result = []\n",
       "    if isinstance(sentence, str):\n",
       "        for word in keywords:\n",
       "            if word.lower() in sentence.lower():\n",
       "                result.append(word)\n",
       "    return result\n",
       "\n",
       "\n",
       "def ngram(l: Iterable[Any], gram: int) -> List[Any]:\n",
       "    l = list(l)\n",
       "    return [l[i: i + gram] for i in range(len(l) - gram + 1)]\n",
       "    \n",
       "    \n",
       "def get_words(line: str, gram: int) -> List[str]:\n",
       "    words = re.findall(r'[a-zA-Z]+', line.lower())\n",
       "    if gram == 1:\n",
       "        stop_words = stopwords.words('english')\n",
       "        words = [word for word in words if word not in stop_words]\n",
       "    else:\n",
       "        words = [' '.join(word) for word in ngram(words, gram)]\n",
       "    return words\n",
       "    \n",
       "    \n",
       "keywords = ['SQL', 'Excel', 'PowerBI', 'Tableau', 'Python', 'Cloud'\n",
       "        , 'Azure', 'AWS', 'GCP', 'API', 'Pipeline', 'Dimension Modelling', 'ETL', 'ELT'\n",
       "        , 'DevOps', 'CI CD', 'Spark', 'Java', 'Scala', 'Oracle', 'Kubernetes', 'Docker'\n",
       "        , 'Apache', 'Kafka', 'Linux', 'Snowflake', 'Data Warehouse'\n",
       "        , 'Data Modelling', 'Data Visualisation', 'Data Migration', 'Data Management'\n",
       "        , 'Data Integration', 'Data Platform', 'Data Architecture', 'Data Factory', 'Databricks', 'Data Science'\n",
       "        , 'Machine Learning', 'Computer Science', 'Research', 'Statistic', 'Mathematics'\n",
       "        , 'Quantitative', 'Algorithm', 'Deep Learning', 'Statistical Analysis'\n",
       "        , 'Communication Skill', 'Stakeholder', 'Reporting', 'Agile'\n",
       "        , 'Project Management', 'Business Intelligence', 'Decision Making', 'Interpersonal'\n",
       "        , 'Time Management', 'Troubleshoot', 'Tertiary Qualification', 'PhD']\n",
       "    \n",
       "\n",
       "keywords_dict = {'SQL':[], 'Excel':[], 'Power BI':[], 'Tableau':[], 'Python':[], 'Cloud':[], 'Azure':[]\n",
       "        , 'AWS':[], 'GCP':[], 'API':[], 'Pipeline':[], 'Dimension Modelling':[], 'ETL':[], 'ELT':[]\n",
       "        , 'DevOps':[], 'CI CD':[], 'Spark':[], 'Java':[], 'Scala':[], 'Oracle': [], 'Kubernetes': []\n",
       "        , 'Docker':[], 'Apache': [], 'Kafka':[], 'Linux':[], 'Snowflake':[], 'Data Warehouse':[]\n",
       "        , 'Data Modelling':[], 'Data Visualisation':[], 'Data Migration':[], 'Data Management':[]\n",
       "        , 'Data Integration':[], 'Data Platform':[], 'Data Architecture':[], 'Data Factory':[], 'Data Science':[]\n",
       "        , 'Machine Learning':[], 'Computer Science':[], 'Research':[], 'Statistic':[], 'Mathematics':[]\n",
       "        , 'Quantitative':[], 'Algorithm':[], 'Deep Learning':[], 'Statistical Analysis':[]\n",
       "        , 'Communication Skill':[], 'Stakeholder': [], 'Reporting':[], 'Agile':[]\n",
       "        , 'Project Management':[], 'Business Intelligence':[], 'Decision Making':[], 'Interpersonal':[]\n",
       "        , 'Time Management':[], 'Troubleshoot':[], 'Tertiary Qualification':[], 'PhD':[]}\n",
       "\n",
       "\n",
       "# read the job details file\n",
       "exsited_keyword = []\n",
       "job_uls = pd.read_csv('data_scientist/seek_data_scientist_job_details_filtered.csv')\n",
       "for ul in job_uls['detail']:\n",
       "    exsited_keyword.append(filtered_keywords(ul))\n",
       "\n",
       "job_uls['exsited_keyword'] = exsited_keyword\n",
       "\n",
       "for index, row in job_uls.iterrows():\n",
       "    if isinstance(row['detail'], str):\n",
       "        for word in get_words(row['detail'], 1):\n",
       "            for skill in keywords:\n",
       "                if word == skill.lower():\n",
       "                    keywords_dict[skill].append(row['line_id'])\n",
       "        for word in get_words(row['detail'], 2):\n",
       "            for skill in keywords:\n",
       "                if word == skill.lower():\n",
       "                    keywords_dict[skill].append(row['line_id'])\n",
       "\n",
       "skill_ranked_line = {}\n",
       "print(keywords_dict)\n",
       "for key, value in keywords_dict.items():\n",
       "    if len(value) != 0:\n",
       "        skill_ranked_line[key] = sum(value) / len(value)\n",
       "    print(key, value)\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for the Average Line_id Count is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Iterable, Any\n",
    "\n",
    "\n",
    "def filtered_keywords(sentence: str) -> list:\n",
    "    result = []\n",
    "    if isinstance(sentence, str):\n",
    "        for word in keywords:\n",
    "            if word.lower() in sentence.lower():\n",
    "                result.append(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "def ngram(l: Iterable[Any], gram: int) -> List[Any]:\n",
    "    l = list(l)\n",
    "    return [l[i: i + gram] for i in range(len(l) - gram + 1)]\n",
    "    \n",
    "    \n",
    "def get_words(line: str, gram: int) -> List[str]:\n",
    "    words = re.findall(r'[a-zA-Z]+', line.lower())\n",
    "    if gram == 1:\n",
    "        stop_words = stopwords.words('english')\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    else:\n",
    "        words = [' '.join(word) for word in ngram(words, gram)]\n",
    "    return words\n",
    "    \n",
    "    \n",
    "keywords = ['SQL', 'Excel', 'PowerBI', 'Tableau', 'Python', 'Cloud'\n",
    "        , 'Azure', 'AWS', 'GCP', 'API', 'Pipeline', 'Dimension Modelling', 'ETL', 'ELT'\n",
    "        , 'DevOps', 'CI CD', 'Spark', 'Java', 'Scala', 'Oracle', 'Kubernetes', 'Docker'\n",
    "        , 'Apache', 'Kafka', 'Linux', 'Snowflake', 'Data Warehouse'\n",
    "        , 'Data Modelling', 'Data Visualisation', 'Data Migration', 'Data Management'\n",
    "        , 'Data Integration', 'Data Platform', 'Data Architecture', 'Data Factory', 'Databricks', 'Data Science'\n",
    "        , 'Machine Learning', 'Computer Science', 'Research', 'Statistic', 'Mathematics'\n",
    "        , 'Quantitative', 'Algorithm', 'Deep Learning', 'Statistical Analysis'\n",
    "        , 'Communication Skill', 'Stakeholder', 'Reporting', 'Agile'\n",
    "        , 'Project Management', 'Business Intelligence', 'Decision Making', 'Interpersonal'\n",
    "        , 'Time Management', 'Troubleshoot', 'Tertiary Qualification', 'PhD']\n",
    "    \n",
    "\n",
    "keywords_dict = {'SQL':[], 'Excel':[], 'Power BI':[], 'Tableau':[], 'Python':[], 'Cloud':[], 'Azure':[]\n",
    "        , 'AWS':[], 'GCP':[], 'API':[], 'Pipeline':[], 'Dimension Modelling':[], 'ETL':[], 'ELT':[]\n",
    "        , 'DevOps':[], 'CI CD':[], 'Spark':[], 'Java':[], 'Scala':[], 'Oracle': [], 'Kubernetes': []\n",
    "        , 'Docker':[], 'Apache': [], 'Kafka':[], 'Linux':[], 'Snowflake':[], 'Data Warehouse':[]\n",
    "        , 'Data Modelling':[], 'Data Visualisation':[], 'Data Migration':[], 'Data Management':[]\n",
    "        , 'Data Integration':[], 'Data Platform':[], 'Data Architecture':[], 'Data Factory':[], 'Data Science':[]\n",
    "        , 'Machine Learning':[], 'Computer Science':[], 'Research':[], 'Statistic':[], 'Mathematics':[]\n",
    "        , 'Quantitative':[], 'Algorithm':[], 'Deep Learning':[], 'Statistical Analysis':[]\n",
    "        , 'Communication Skill':[], 'Stakeholder': [], 'Reporting':[], 'Agile':[]\n",
    "        , 'Project Management':[], 'Business Intelligence':[], 'Decision Making':[], 'Interpersonal':[]\n",
    "        , 'Time Management':[], 'Troubleshoot':[], 'Tertiary Qualification':[], 'PhD':[]}\n",
    "\n",
    "\n",
    "# read the job details file\n",
    "exsited_keyword = []\n",
    "job_uls = pd.read_csv('data_scientist/seek_data_scientist_job_details_filtered.csv')\n",
    "for ul in job_uls['detail']:\n",
    "    exsited_keyword.append(filtered_keywords(ul))\n",
    "\n",
    "job_uls['exsited_keyword'] = exsited_keyword\n",
    "\n",
    "for index, row in job_uls.iterrows():\n",
    "    if isinstance(row['detail'], str):\n",
    "        for word in get_words(row['detail'], 1):\n",
    "            for skill in keywords:\n",
    "                if word == skill.lower():\n",
    "                    keywords_dict[skill].append(row['line_id'])\n",
    "        for word in get_words(row['detail'], 2):\n",
    "            for skill in keywords:\n",
    "                if word == skill.lower():\n",
    "                    keywords_dict[skill].append(row['line_id'])\n",
    "\n",
    "skill_ranked_line = {}\n",
    "print(keywords_dict)\n",
    "for key, value in keywords_dict.items():\n",
    "    if len(value) != 0:\n",
    "        skill_ranked_line[key] = sum(value) / len(value)\n",
    "    print(key, value)\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for the Average Line_id Count is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "\n",
       "---\n",
       "\n",
       "```sql\n",
       "WITH \n",
       "enriched AS (\n",
       "\tSELECT job_id, job_title\n",
       "\t\t\t, CASE \n",
       "\t\t\tWHEN job_title LIKE '%data%analyst%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title LIKE '%bi%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title LIKE '%tableau%'  THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%sql%' THEN 'data analyst'\t\t\n",
       "\t\t\tWHEN job_title LIKE '%analytic%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%data%modeller%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%visualisation%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%business%intelligence%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title like '%insight%' THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%reporting%' THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%model%' THEN 'data analyst'\n",
       "\t\t\t\n",
       "\t\t\tWHEN job_title like '%data%engineer%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%warehouse%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%architect%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%snowflake%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%etl%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%api%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%cloud%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%aws%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%kafka%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%pipeline%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%migration%' THEN 'data engineer'\n",
       "\t\t\t\n",
       "\t\t\tWHEN job_title like '%scientist%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%science%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%machine%learning%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '% ai%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%ai %' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%ml%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%computational%statistics%' then 'data scientist'\n",
       "\t\t\tWHEN job_title like '%quantitative%' then 'data scientist'\n",
       "\t\t\tWHEN job_title like '%artificial%intelligence%' then 'data scientist'\n",
       "\t\t\t\n",
       "\t\t\tWHEN job_title like '%business%analyst%' THEN 'else'\n",
       "\t\t\tWHEN job_title like '%accountant%' THEN 'else'\n",
       "\t\t\tWHEN job_title like '%sales%' THEN 'else'\n",
       "\t\t\tWHEN job_title like '%product%' THEN 'else'\n",
       "\t\t\tWHEN job_title like '%dev%ops%' THEN 'else'\n",
       "\t\t\tWHEN job_title like '%graduate%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%developer%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%functional%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%financial%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%finance%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%manager%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%project%' THEN 'else'\n",
       "\t\t\tWHEN job_title LIKE '%program%' THEN 'else'\n",
       "\t\t\t\n",
       "\t\t\tEND AS job_standard_name\n",
       "\tFROM dim_job_info\n",
       "\tORDER BY 2 DESC\n",
       "\t)\n",
       "\n",
       ", filtered_job_details AS (\n",
       "\tSELECT *\n",
       "\tFROM dim_job_details\n",
       "\tWHERE job_id IN (\n",
       "\t\tSELECT job_id FROM enriched \n",
       "-- \t\tWHERE job_standard_name = 'data analyst' )\n",
       "-- \t\tWHERE job_standard_name = 'data engineer' )\n",
       "\t\tWHERE job_standard_name = 'data scientist' )\n",
       "\t)\n",
       "\n",
       ", enriched_details AS (\n",
       "\tSELECT *\n",
       "\t\t, CASE WHEN detail LIKE '%sql%' THEN '1' END AS sql_counter\n",
       "\t\t, CASE WHEN detail LIKE '%excel%' THEN '1' END AS excel_counter\n",
       "\t\t, CASE WHEN detail LIKE '%power%bi%' THEN '1' END AS powerbi_counter\n",
       "\t\t, CASE WHEN detail LIKE '%tableau%' THEN '1' END AS tableau_counter\n",
       "\t\t, CASE WHEN detail LIKE '%python%' THEN '1' END AS python_counter\n",
       "\t\t, CASE WHEN detail LIKE '%cloud%' THEN '1' END AS cloud_counter\n",
       "\t\t, CASE WHEN detail LIKE '%azure%' THEN '1' END AS azure_counter\n",
       "\t\t, CASE WHEN detail LIKE '%aws%' THEN '1' END AS aws_counter\n",
       "\t\t, CASE WHEN detail LIKE '%gcp%' THEN '1' END AS gcp_counter\n",
       "\t\t\n",
       "\t\t, CASE WHEN detail LIKE '%api%' THEN '1' END AS api_counter\n",
       "\t\t, CASE WHEN detail LIKE '%pipeline%' THEN '1' END AS pipeline_counter\n",
       "\t\t, CASE WHEN detail LIKE '%dimension%' THEN '1' END AS dimension_counter\n",
       "\t\t, CASE WHEN detail LIKE '%etl%' THEN '1' END AS etl_counter\n",
       "\t\t, CASE WHEN detail LIKE '%elt%' THEN '1' END AS elt_counter\n",
       "\t\t, CASE WHEN detail LIKE '%devops%' THEN '1' END AS devops_counter\n",
       "\t\t, CASE WHEN detail LIKE '%ci%cd%' THEN '1' END AS cicd_counter\n",
       "\t\t, CASE WHEN detail LIKE '%spark%' THEN '1' END AS spark_counter\n",
       "\t\t, CASE WHEN detail LIKE '%java%' THEN '1' END AS java_counter\n",
       "\t\t, CASE WHEN detail LIKE '%scala%' THEN '1' END AS scala_counter\n",
       "\t\t, CASE WHEN detail LIKE '%kafka%' THEN '1' END AS kafka_counter\n",
       "\t\t, CASE WHEN detail LIKE '%linux%' THEN '1' END AS linux_counter\n",
       "\t\t, CASE WHEN detail LIKE '%snowflake%' THEN '1' END AS snowflake_counter\t\n",
       "\t\t, CASE WHEN detail LIKE '%oracle%' THEN '1' END AS oracle_counter\n",
       "\t\t, CASE WHEN detail LIKE '%kubernetes%' THEN '1' END AS kubernetes_counter\n",
       "\t\t, CASE WHEN detail LIKE '%docker%' THEN '1' END AS docker_counter\n",
       "\t\t, CASE WHEN detail LIKE '%apache%' THEN '1' END AS apache_counter\n",
       "\t\t\n",
       "\t\t, CASE WHEN detail LIKE '%data%warehous%' THEN '1' END AS DW_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%modelling%' THEN '1' END AS DM_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%visualisation%' THEN '1' END AS DV_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%migration%' THEN '1' END AS DMI_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%management%' THEN '1' END AS DMA_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%integration%' THEN '1' END AS DI_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%platform%' THEN '1' END AS DP_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%architecture%' THEN '1' END AS DA_counter\n",
       "\t\t, CASE WHEN detail LIKE '%data%factory%' THEN '1' END AS DF_counter\n",
       "\t\t, CASE WHEN detail LIKE '%databricks%' THEN '1' END AS DB_counter\n",
       "\t\t\n",
       "\t\t, CASE WHEN detail LIKE '%data%science%' THEN '1' END AS DS_counter\n",
       "\t\t, CASE WHEN detail LIKE '%machine%learning%' THEN '1' END AS ML_counter\n",
       "\t\t, CASE WHEN detail LIKE '% ai %' THEN '1' END AS AI_counter\n",
       "\t\t, CASE WHEN detail LIKE '%computer%science%' THEN '1' END AS CS_counter\n",
       "\t\t, CASE WHEN detail LIKE '%research%' THEN '1' END AS research_counter\n",
       "\t\t, CASE WHEN detail LIKE '%statistic%' THEN '1' END AS statistic_counter\n",
       "\t\t, CASE WHEN detail LIKE '%mathematics%' THEN '1' END AS mathematics_counter\n",
       "\t\t, CASE WHEN detail LIKE '%quantitative%' THEN '1' END AS quantitative_counter\n",
       "\t\t, CASE WHEN detail LIKE '%algorithm%' THEN '1' END AS algorithm_counter\n",
       "\t\t, CASE WHEN detail LIKE '%deep%learning%' THEN '1' END AS DL_counter\n",
       "\t\t, CASE WHEN detail LIKE '%statistical%analysis%' THEN '1' END AS SA_counter\n",
       "        \n",
       "        , CASE WHEN detail LIKE '%communication%' THEN '1' END AS communication_counter\n",
       "\t\t, CASE WHEN detail LIKE '%reporting%' THEN '1' END AS reporting_counter\n",
       "\t\t, CASE WHEN detail LIKE '%agile%' THEN '1' END AS agile_counter\n",
       "\t\t\n",
       "\t\t, CASE WHEN detail LIKE '%stakeholder%' THEN '1' END AS stakeholder_counter\n",
       "\t\t, CASE WHEN detail LIKE '%project%management%' THEN '1' END AS PM_counter\n",
       "\t\t, CASE WHEN detail LIKE '%decision%making%' THEN '1' END AS DM_counter\n",
       "\t\t, CASE WHEN detail LIKE '%interpersonal%skills%' THEN '1' END AS IS_counter\n",
       "\t\t, CASE WHEN detail LIKE '%time%management%' THEN '1' END AS TM_counter\n",
       "\t\t, CASE WHEN detail LIKE '%troubleshoot%' THEN '1' END AS troubleshoot_counter\n",
       "\t\t, CASE WHEN detail LIKE '%tertiary%qualification%' THEN '1' END AS TQ_counter\n",
       "\t\t, CASE WHEN detail LIKE '%phd%' THEN '1' END AS phd_counter\n",
       "\t\t, CASE WHEN detail LIKE '%business%intelligence%' THEN '1' END AS BI_counter\n",
       "\n",
       "\tFROM filtered_job_details\n",
       "\t)\n",
       ", job_details AS (\n",
       "\tSELECT job_id\n",
       "\t\t, SUM(sql_counter) > 0 AS has_sql\n",
       "\t\t, SUM(excel_counter) > 0 AS has_excel\n",
       "\t\t, SUM(powerbi_counter) > 0 AS has_powerbi\n",
       "\t\t, SUM(tableau_counter) > 0 AS has_tableau\n",
       "\t\t, SUM(python_counter) > 0 AS has_python\n",
       "\t\t, SUM(cloud_counter) > 0 AS has_cloud\n",
       "\t\t, SUM(azure_counter) > 0 AS has_azure\n",
       "\t\t, SUM(aws_counter) > 0 AS has_aws\n",
       "\t\t, SUM(gcp_counter) > 0 AS has_gcp\n",
       "\t\t\n",
       "\t\t, SUM(api_counter) > 0 AS has_api\n",
       "\t\t, SUM(pipeline_counter) > 0 AS has_pipeline\n",
       "\t\t, SUM(dimension_counter) > 0 AS has_dimension\n",
       "\t\t, SUM(etl_counter) > 0 AS has_etl\n",
       "\t\t, SUM(elt_counter) > 0 AS has_elt\n",
       "\t\t, SUM(devops_counter) > 0 AS has_devops\n",
       "\t\t, SUM(cicd_counter) > 0 AS has_cicd\n",
       "\t\t, SUM(spark_counter) > 0 AS has_spark\n",
       "\t\t, SUM(java_counter) > 0 AS has_java\n",
       "\t\t, SUM(scala_counter) > 0 AS has_scala\n",
       "\t\t, SUM(kafka_counter) > 0 AS has_kafka\n",
       "\t\t, SUM(linux_counter) > 0 AS has_linux\n",
       "\t\t, SUM(snowflake_counter) > 0 AS has_snowflake\n",
       "\t\t, SUM(oracle_counter) > 0 AS has_oracle\n",
       "\t\t, SUM(kubernetes_counter) > 0 AS has_kubernetes\n",
       "\t\t, SUM(docker_counter) > 0 AS has_docker\n",
       "\t\t, SUM(apache_counter) > 0 AS has_apache\n",
       "\n",
       "\t\t, SUM(DW_counter) > 0 AS has_DW\n",
       "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
       "\t\t, SUM(DV_counter) > 0 AS has_DV\n",
       "\t\t, SUM(DMI_counter) > 0 AS has_DMI\n",
       "\t\t, SUM(DMA_counter) > 0 AS has_DMA\n",
       "\t\t, SUM(DI_counter) > 0 AS has_DI\n",
       "\t\t, SUM(DP_counter) > 0 AS has_DP\n",
       "\t\t, SUM(DA_counter) > 0 AS has_DA\n",
       "\t\t, SUM(DF_counter) > 0 AS has_DF\n",
       "\t\t, SUM(DB_counter) > 0 AS has_DB\n",
       "\t\t\n",
       "\t\t, SUM(DS_counter) > 0 AS has_DS\n",
       "\t\t, SUM(ML_counter) > 0 AS has_ML\n",
       "\t\t, SUM(AI_counter) > 0 AS has_AI\n",
       "\t\t, SUM(CS_counter) > 0 AS has_CS\n",
       "\t\t, SUM(research_counter) > 0 AS has_research\n",
       "\t\t, SUM(statistic_counter) > 0 AS has_statistic\n",
       "\t\t, SUM(mathematics_counter) > 0 AS has_mathematics\n",
       "\t\t, SUM(quantitative_counter) > 0 AS has_quantitative\n",
       "\t\t, SUM(algorithm_counter) > 0 AS has_algorithm\n",
       "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
       "\t\t, SUM(SA_counter) > 0 AS has_SA\n",
       "        \n",
       "        , SUM(communication_counter) > 0 AS has_communication\n",
       "\t\t, SUM(reporting_counter) > 0 AS has_reporting\n",
       "\t\t, SUM(agile_counter) > 0 AS has_agile\n",
       "\t\t, SUM(stakeholder_counter) > 0 AS has_stakeholder\n",
       "\t\t, SUM(PM_counter) > 0 AS has_PM\n",
       "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
       "\t\t, SUM(IS_counter) > 0 AS has_IS\n",
       "\t\t, SUM(TM_counter) > 0 AS has_TM\n",
       "\t\t, SUM(troubleshoot_counter) > 0 AS has_troubleshoot\n",
       "\t\t, SUM(TQ_counter) > 0 AS has_TQ\n",
       "\t\t, SUM(phd_counter) > 0 AS has_phd\n",
       "\t\t, SUM(BI_counter) > 0 AS has_BI\n",
       "\n",
       "\tFROM enriched_details\n",
       "\tGROUP BY job_id\n",
       "\t)\n",
       "\n",
       "SELECT \n",
       "(SELECT COUNT(DISTINCT job_id) FROM filtered_job_details) AS total_jobs\n",
       "\t, SUM(has_sql) AS sql_jobs\n",
       "\t, SUM(has_excel) AS excel_jobs\n",
       "\t, SUM(has_powerbi) AS powerbi_jobs\n",
       "\t, SUM(has_tableau) AS tableau_jobs\n",
       "\t, SUM(has_python) AS python_jobs\n",
       "\t, SUM(has_cloud) AS cloud_jobs\n",
       "\t, SUM(has_azure) AS azure_jobs\n",
       "\t, SUM(has_aws) AS aws_jobs\n",
       "\t, SUM(has_gcp) AS gcp_jobs\n",
       "\t\n",
       "\t, SUM(has_api) AS api_jobs\n",
       "\t, SUM(has_pipeline) AS pipeline_jobs\n",
       "\t, SUM(has_dimension) AS dimension_jobs\n",
       "\t, SUM(has_etl) AS etl_jobs\n",
       "\t, SUM(has_elt) AS elt_jobs\n",
       "\t, SUM(has_devops) AS devops_jobs\n",
       "\t, SUM(has_cicd) AS cicd_jobs\n",
       "\t, SUM(has_spark) AS spark_jobs\n",
       "\t, SUM(has_java) AS java_jobs\n",
       "\t, SUM(has_scala) AS scala_jobs\n",
       "\t, SUM(has_kafka) AS kafka_jobs\n",
       "\t, SUM(has_linux) AS linux_jobs\n",
       "\t, SUM(has_snowflake) AS snowflake_jobs\n",
       "\t, SUM(has_oracle) AS oracle_jobs\n",
       "\t, SUM(has_kubernetes) AS kubernetes_jobs\n",
       "\t, SUM(has_docker) AS docker_jobs\n",
       "\t, SUM(has_apache) AS apache_jobs\n",
       "\n",
       "\t, SUM(has_DW) AS datawarehouse_jobs\n",
       "\t, SUM(has_DM) AS datamodelling_jobs\n",
       "\t, SUM(has_DV) AS datavisualisation_jobs\n",
       "\t, SUM(has_DMI) AS datamigration_jobs\n",
       "\t, SUM(has_DMA) AS datamanagement_jobs\n",
       "\t, SUM(has_DI) AS dataintegration_jobs\n",
       "\t, SUM(has_DP) AS dataplatform_jobs\n",
       "\t, SUM(has_DA) AS dataarchitecture_jobs\n",
       "\t, SUM(has_DF) AS datafactory_jobs\n",
       "\t, SUM(has_DB) AS databricks_jobs\n",
       "\t\n",
       "\t, SUM(has_DS) AS datascience_jobs\n",
       "\t, SUM(has_ML) AS machinelearning_jobs\n",
       "\t, SUM(has_AI) AS Artificialintelligence_jobs\n",
       "\t, SUM(has_CS) AS computerscience_jobs\n",
       "\t, SUM(has_research) AS research_jobs\n",
       "\t, SUM(has_statistic) AS statistic_jobs\n",
       "\t, SUM(has_mathematics) AS mathematics_jobs\n",
       "\t, SUM(has_quantitative) AS quantitative_jobs\n",
       "\t, SUM(has_algorithm) AS algorithm_jobs\n",
       "\t, SUM(has_DM) AS deeplearning_jobs\n",
       "\t, SUM(has_SA) AS statisticalanalysis_jobs\n",
       "    \n",
       "    , SUM(has_communication) AS Communication_Skill\n",
       "\t, SUM(has_reporting) AS Reporting\n",
       "\t, SUM(has_agile) AS Agile\n",
       "\t, SUM(has_stakeholder) AS Stakeholder\n",
       "\t, SUM(has_PM) AS Project_Management\n",
       "\t, SUM(has_BI) AS Business_Intelligence\n",
       "\t, SUM(has_DM) AS Decision_Making\n",
       "\t, SUM(has_IS) AS Interpersonal_Skill\n",
       "\t, SUM(has_TM) AS Time_Management\n",
       "\t, SUM(has_troubleshoot) AS Troubleshooting\n",
       "\t, SUM(has_TQ) AS Tertiary_Qualification\n",
       "\t, SUM(has_phd) AS PhD\n",
       "    \n",
       "\t\n",
       "FROM job_details\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for Filtering the Related Recruitment Data for DA, DE and DS and Necessary Skills is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "\n",
    "---\n",
    "\n",
    "```sql\n",
    "WITH \n",
    "enriched AS (\n",
    "\tSELECT job_id, job_title\n",
    "\t\t\t, CASE \n",
    "\t\t\tWHEN job_title LIKE '%data%analyst%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title LIKE '%bi%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title LIKE '%tableau%'  THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%sql%' THEN 'data analyst'\t\t\n",
    "\t\t\tWHEN job_title LIKE '%analytic%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%data%modeller%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%visualisation%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%business%intelligence%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title like '%insight%' THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%reporting%' THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%model%' THEN 'data analyst'\n",
    "\t\t\t\n",
    "\t\t\tWHEN job_title like '%data%engineer%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%warehouse%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%architect%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%snowflake%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%etl%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%api%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%cloud%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%aws%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%kafka%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%pipeline%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%migration%' THEN 'data engineer'\n",
    "\t\t\t\n",
    "\t\t\tWHEN job_title like '%scientist%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%science%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%machine%learning%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '% ai%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%ai %' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%ml%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%computational%statistics%' then 'data scientist'\n",
    "\t\t\tWHEN job_title like '%quantitative%' then 'data scientist'\n",
    "\t\t\tWHEN job_title like '%artificial%intelligence%' then 'data scientist'\n",
    "\t\t\t\n",
    "\t\t\tWHEN job_title like '%business%analyst%' THEN 'else'\n",
    "\t\t\tWHEN job_title like '%accountant%' THEN 'else'\n",
    "\t\t\tWHEN job_title like '%sales%' THEN 'else'\n",
    "\t\t\tWHEN job_title like '%product%' THEN 'else'\n",
    "\t\t\tWHEN job_title like '%dev%ops%' THEN 'else'\n",
    "\t\t\tWHEN job_title like '%graduate%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%developer%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%functional%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%financial%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%finance%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%manager%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%project%' THEN 'else'\n",
    "\t\t\tWHEN job_title LIKE '%program%' THEN 'else'\n",
    "\t\t\t\n",
    "\t\t\tEND AS job_standard_name\n",
    "\tFROM dim_job_info\n",
    "\tORDER BY 2 DESC\n",
    "\t)\n",
    "\n",
    ", filtered_job_details AS (\n",
    "\tSELECT *\n",
    "\tFROM dim_job_details\n",
    "\tWHERE job_id IN (\n",
    "\t\tSELECT job_id FROM enriched \n",
    "-- \t\tWHERE job_standard_name = 'data analyst' )\n",
    "-- \t\tWHERE job_standard_name = 'data engineer' )\n",
    "\t\tWHERE job_standard_name = 'data scientist' )\n",
    "\t)\n",
    "\n",
    ", enriched_details AS (\n",
    "\tSELECT *\n",
    "\t\t, CASE WHEN detail LIKE '%sql%' THEN '1' END AS sql_counter\n",
    "\t\t, CASE WHEN detail LIKE '%excel%' THEN '1' END AS excel_counter\n",
    "\t\t, CASE WHEN detail LIKE '%power%bi%' THEN '1' END AS powerbi_counter\n",
    "\t\t, CASE WHEN detail LIKE '%tableau%' THEN '1' END AS tableau_counter\n",
    "\t\t, CASE WHEN detail LIKE '%python%' THEN '1' END AS python_counter\n",
    "\t\t, CASE WHEN detail LIKE '%cloud%' THEN '1' END AS cloud_counter\n",
    "\t\t, CASE WHEN detail LIKE '%azure%' THEN '1' END AS azure_counter\n",
    "\t\t, CASE WHEN detail LIKE '%aws%' THEN '1' END AS aws_counter\n",
    "\t\t, CASE WHEN detail LIKE '%gcp%' THEN '1' END AS gcp_counter\n",
    "\t\t\n",
    "\t\t, CASE WHEN detail LIKE '%api%' THEN '1' END AS api_counter\n",
    "\t\t, CASE WHEN detail LIKE '%pipeline%' THEN '1' END AS pipeline_counter\n",
    "\t\t, CASE WHEN detail LIKE '%dimension%' THEN '1' END AS dimension_counter\n",
    "\t\t, CASE WHEN detail LIKE '%etl%' THEN '1' END AS etl_counter\n",
    "\t\t, CASE WHEN detail LIKE '%elt%' THEN '1' END AS elt_counter\n",
    "\t\t, CASE WHEN detail LIKE '%devops%' THEN '1' END AS devops_counter\n",
    "\t\t, CASE WHEN detail LIKE '%ci%cd%' THEN '1' END AS cicd_counter\n",
    "\t\t, CASE WHEN detail LIKE '%spark%' THEN '1' END AS spark_counter\n",
    "\t\t, CASE WHEN detail LIKE '%java%' THEN '1' END AS java_counter\n",
    "\t\t, CASE WHEN detail LIKE '%scala%' THEN '1' END AS scala_counter\n",
    "\t\t, CASE WHEN detail LIKE '%kafka%' THEN '1' END AS kafka_counter\n",
    "\t\t, CASE WHEN detail LIKE '%linux%' THEN '1' END AS linux_counter\n",
    "\t\t, CASE WHEN detail LIKE '%snowflake%' THEN '1' END AS snowflake_counter\t\n",
    "\t\t, CASE WHEN detail LIKE '%oracle%' THEN '1' END AS oracle_counter\n",
    "\t\t, CASE WHEN detail LIKE '%kubernetes%' THEN '1' END AS kubernetes_counter\n",
    "\t\t, CASE WHEN detail LIKE '%docker%' THEN '1' END AS docker_counter\n",
    "\t\t, CASE WHEN detail LIKE '%apache%' THEN '1' END AS apache_counter\n",
    "\t\t\n",
    "\t\t, CASE WHEN detail LIKE '%data%warehous%' THEN '1' END AS DW_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%modelling%' THEN '1' END AS DM_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%visualisation%' THEN '1' END AS DV_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%migration%' THEN '1' END AS DMI_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%management%' THEN '1' END AS DMA_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%integration%' THEN '1' END AS DI_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%platform%' THEN '1' END AS DP_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%architecture%' THEN '1' END AS DA_counter\n",
    "\t\t, CASE WHEN detail LIKE '%data%factory%' THEN '1' END AS DF_counter\n",
    "\t\t, CASE WHEN detail LIKE '%databricks%' THEN '1' END AS DB_counter\n",
    "\t\t\n",
    "\t\t, CASE WHEN detail LIKE '%data%science%' THEN '1' END AS DS_counter\n",
    "\t\t, CASE WHEN detail LIKE '%machine%learning%' THEN '1' END AS ML_counter\n",
    "\t\t, CASE WHEN detail LIKE '% ai %' THEN '1' END AS AI_counter\n",
    "\t\t, CASE WHEN detail LIKE '%computer%science%' THEN '1' END AS CS_counter\n",
    "\t\t, CASE WHEN detail LIKE '%research%' THEN '1' END AS research_counter\n",
    "\t\t, CASE WHEN detail LIKE '%statistic%' THEN '1' END AS statistic_counter\n",
    "\t\t, CASE WHEN detail LIKE '%mathematics%' THEN '1' END AS mathematics_counter\n",
    "\t\t, CASE WHEN detail LIKE '%quantitative%' THEN '1' END AS quantitative_counter\n",
    "\t\t, CASE WHEN detail LIKE '%algorithm%' THEN '1' END AS algorithm_counter\n",
    "\t\t, CASE WHEN detail LIKE '%deep%learning%' THEN '1' END AS DL_counter\n",
    "\t\t, CASE WHEN detail LIKE '%statistical%analysis%' THEN '1' END AS SA_counter\n",
    "        \n",
    "        , CASE WHEN detail LIKE '%communication%' THEN '1' END AS communication_counter\n",
    "\t\t, CASE WHEN detail LIKE '%reporting%' THEN '1' END AS reporting_counter\n",
    "\t\t, CASE WHEN detail LIKE '%agile%' THEN '1' END AS agile_counter\n",
    "\t\t\n",
    "\t\t, CASE WHEN detail LIKE '%stakeholder%' THEN '1' END AS stakeholder_counter\n",
    "\t\t, CASE WHEN detail LIKE '%project%management%' THEN '1' END AS PM_counter\n",
    "\t\t, CASE WHEN detail LIKE '%decision%making%' THEN '1' END AS DM_counter\n",
    "\t\t, CASE WHEN detail LIKE '%interpersonal%skills%' THEN '1' END AS IS_counter\n",
    "\t\t, CASE WHEN detail LIKE '%time%management%' THEN '1' END AS TM_counter\n",
    "\t\t, CASE WHEN detail LIKE '%troubleshoot%' THEN '1' END AS troubleshoot_counter\n",
    "\t\t, CASE WHEN detail LIKE '%tertiary%qualification%' THEN '1' END AS TQ_counter\n",
    "\t\t, CASE WHEN detail LIKE '%phd%' THEN '1' END AS phd_counter\n",
    "\t\t, CASE WHEN detail LIKE '%business%intelligence%' THEN '1' END AS BI_counter\n",
    "\n",
    "\tFROM filtered_job_details\n",
    "\t)\n",
    ", job_details AS (\n",
    "\tSELECT job_id\n",
    "\t\t, SUM(sql_counter) > 0 AS has_sql\n",
    "\t\t, SUM(excel_counter) > 0 AS has_excel\n",
    "\t\t, SUM(powerbi_counter) > 0 AS has_powerbi\n",
    "\t\t, SUM(tableau_counter) > 0 AS has_tableau\n",
    "\t\t, SUM(python_counter) > 0 AS has_python\n",
    "\t\t, SUM(cloud_counter) > 0 AS has_cloud\n",
    "\t\t, SUM(azure_counter) > 0 AS has_azure\n",
    "\t\t, SUM(aws_counter) > 0 AS has_aws\n",
    "\t\t, SUM(gcp_counter) > 0 AS has_gcp\n",
    "\t\t\n",
    "\t\t, SUM(api_counter) > 0 AS has_api\n",
    "\t\t, SUM(pipeline_counter) > 0 AS has_pipeline\n",
    "\t\t, SUM(dimension_counter) > 0 AS has_dimension\n",
    "\t\t, SUM(etl_counter) > 0 AS has_etl\n",
    "\t\t, SUM(elt_counter) > 0 AS has_elt\n",
    "\t\t, SUM(devops_counter) > 0 AS has_devops\n",
    "\t\t, SUM(cicd_counter) > 0 AS has_cicd\n",
    "\t\t, SUM(spark_counter) > 0 AS has_spark\n",
    "\t\t, SUM(java_counter) > 0 AS has_java\n",
    "\t\t, SUM(scala_counter) > 0 AS has_scala\n",
    "\t\t, SUM(kafka_counter) > 0 AS has_kafka\n",
    "\t\t, SUM(linux_counter) > 0 AS has_linux\n",
    "\t\t, SUM(snowflake_counter) > 0 AS has_snowflake\n",
    "\t\t, SUM(oracle_counter) > 0 AS has_oracle\n",
    "\t\t, SUM(kubernetes_counter) > 0 AS has_kubernetes\n",
    "\t\t, SUM(docker_counter) > 0 AS has_docker\n",
    "\t\t, SUM(apache_counter) > 0 AS has_apache\n",
    "\n",
    "\t\t, SUM(DW_counter) > 0 AS has_DW\n",
    "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
    "\t\t, SUM(DV_counter) > 0 AS has_DV\n",
    "\t\t, SUM(DMI_counter) > 0 AS has_DMI\n",
    "\t\t, SUM(DMA_counter) > 0 AS has_DMA\n",
    "\t\t, SUM(DI_counter) > 0 AS has_DI\n",
    "\t\t, SUM(DP_counter) > 0 AS has_DP\n",
    "\t\t, SUM(DA_counter) > 0 AS has_DA\n",
    "\t\t, SUM(DF_counter) > 0 AS has_DF\n",
    "\t\t, SUM(DB_counter) > 0 AS has_DB\n",
    "\t\t\n",
    "\t\t, SUM(DS_counter) > 0 AS has_DS\n",
    "\t\t, SUM(ML_counter) > 0 AS has_ML\n",
    "\t\t, SUM(AI_counter) > 0 AS has_AI\n",
    "\t\t, SUM(CS_counter) > 0 AS has_CS\n",
    "\t\t, SUM(research_counter) > 0 AS has_research\n",
    "\t\t, SUM(statistic_counter) > 0 AS has_statistic\n",
    "\t\t, SUM(mathematics_counter) > 0 AS has_mathematics\n",
    "\t\t, SUM(quantitative_counter) > 0 AS has_quantitative\n",
    "\t\t, SUM(algorithm_counter) > 0 AS has_algorithm\n",
    "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
    "\t\t, SUM(SA_counter) > 0 AS has_SA\n",
    "        \n",
    "        , SUM(communication_counter) > 0 AS has_communication\n",
    "\t\t, SUM(reporting_counter) > 0 AS has_reporting\n",
    "\t\t, SUM(agile_counter) > 0 AS has_agile\n",
    "\t\t, SUM(stakeholder_counter) > 0 AS has_stakeholder\n",
    "\t\t, SUM(PM_counter) > 0 AS has_PM\n",
    "\t\t, SUM(DM_counter) > 0 AS has_DM\n",
    "\t\t, SUM(IS_counter) > 0 AS has_IS\n",
    "\t\t, SUM(TM_counter) > 0 AS has_TM\n",
    "\t\t, SUM(troubleshoot_counter) > 0 AS has_troubleshoot\n",
    "\t\t, SUM(TQ_counter) > 0 AS has_TQ\n",
    "\t\t, SUM(phd_counter) > 0 AS has_phd\n",
    "\t\t, SUM(BI_counter) > 0 AS has_BI\n",
    "\n",
    "\tFROM enriched_details\n",
    "\tGROUP BY job_id\n",
    "\t)\n",
    "\n",
    "SELECT \n",
    "(SELECT COUNT(DISTINCT job_id) FROM filtered_job_details) AS total_jobs\n",
    "\t, SUM(has_sql) AS sql_jobs\n",
    "\t, SUM(has_excel) AS excel_jobs\n",
    "\t, SUM(has_powerbi) AS powerbi_jobs\n",
    "\t, SUM(has_tableau) AS tableau_jobs\n",
    "\t, SUM(has_python) AS python_jobs\n",
    "\t, SUM(has_cloud) AS cloud_jobs\n",
    "\t, SUM(has_azure) AS azure_jobs\n",
    "\t, SUM(has_aws) AS aws_jobs\n",
    "\t, SUM(has_gcp) AS gcp_jobs\n",
    "\t\n",
    "\t, SUM(has_api) AS api_jobs\n",
    "\t, SUM(has_pipeline) AS pipeline_jobs\n",
    "\t, SUM(has_dimension) AS dimension_jobs\n",
    "\t, SUM(has_etl) AS etl_jobs\n",
    "\t, SUM(has_elt) AS elt_jobs\n",
    "\t, SUM(has_devops) AS devops_jobs\n",
    "\t, SUM(has_cicd) AS cicd_jobs\n",
    "\t, SUM(has_spark) AS spark_jobs\n",
    "\t, SUM(has_java) AS java_jobs\n",
    "\t, SUM(has_scala) AS scala_jobs\n",
    "\t, SUM(has_kafka) AS kafka_jobs\n",
    "\t, SUM(has_linux) AS linux_jobs\n",
    "\t, SUM(has_snowflake) AS snowflake_jobs\n",
    "\t, SUM(has_oracle) AS oracle_jobs\n",
    "\t, SUM(has_kubernetes) AS kubernetes_jobs\n",
    "\t, SUM(has_docker) AS docker_jobs\n",
    "\t, SUM(has_apache) AS apache_jobs\n",
    "\n",
    "\t, SUM(has_DW) AS datawarehouse_jobs\n",
    "\t, SUM(has_DM) AS datamodelling_jobs\n",
    "\t, SUM(has_DV) AS datavisualisation_jobs\n",
    "\t, SUM(has_DMI) AS datamigration_jobs\n",
    "\t, SUM(has_DMA) AS datamanagement_jobs\n",
    "\t, SUM(has_DI) AS dataintegration_jobs\n",
    "\t, SUM(has_DP) AS dataplatform_jobs\n",
    "\t, SUM(has_DA) AS dataarchitecture_jobs\n",
    "\t, SUM(has_DF) AS datafactory_jobs\n",
    "\t, SUM(has_DB) AS databricks_jobs\n",
    "\t\n",
    "\t, SUM(has_DS) AS datascience_jobs\n",
    "\t, SUM(has_ML) AS machinelearning_jobs\n",
    "\t, SUM(has_AI) AS Artificialintelligence_jobs\n",
    "\t, SUM(has_CS) AS computerscience_jobs\n",
    "\t, SUM(has_research) AS research_jobs\n",
    "\t, SUM(has_statistic) AS statistic_jobs\n",
    "\t, SUM(has_mathematics) AS mathematics_jobs\n",
    "\t, SUM(has_quantitative) AS quantitative_jobs\n",
    "\t, SUM(has_algorithm) AS algorithm_jobs\n",
    "\t, SUM(has_DM) AS deeplearning_jobs\n",
    "\t, SUM(has_SA) AS statisticalanalysis_jobs\n",
    "    \n",
    "    , SUM(has_communication) AS Communication_Skill\n",
    "\t, SUM(has_reporting) AS Reporting\n",
    "\t, SUM(has_agile) AS Agile\n",
    "\t, SUM(has_stakeholder) AS Stakeholder\n",
    "\t, SUM(has_PM) AS Project_Management\n",
    "\t, SUM(has_BI) AS Business_Intelligence\n",
    "\t, SUM(has_DM) AS Decision_Making\n",
    "\t, SUM(has_IS) AS Interpersonal_Skill\n",
    "\t, SUM(has_TM) AS Time_Management\n",
    "\t, SUM(has_troubleshoot) AS Troubleshooting\n",
    "\t, SUM(has_TQ) AS Tertiary_Qualification\n",
    "\t, SUM(has_phd) AS PhD\n",
    "    \n",
    "\t\n",
    "FROM job_details\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for Filtering the Related Recruitment Data for DA, DE and DS and Necessary Skills is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       "\n",
       "---\n",
       "\n",
       "```sql\n",
       "\n",
       "WITH \n",
       "enriched AS (\n",
       "\tSELECT job_id, job_title\n",
       "\t\t\t, CASE \n",
       "\t\t\tWHEN job_title LIKE '%data%analyst%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title LIKE '%bi%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title LIKE '%tableau%'  THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%sql%' THEN 'data analyst'\t\t\n",
       "\t\t\tWHEN job_title LIKE '%analytic%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%data%modeller%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%visualisation%'  THEN 'data analyst' \n",
       "\t\t\tWHEN job_title LIKE '%business%intelligence%'  THEN 'data analyst'  \n",
       "\t\t\tWHEN job_title like '%insight%' THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%reporting%' THEN 'data analyst'\n",
       "\t\t\tWHEN job_title like '%model%' THEN 'data analyst'\n",
       "\t\t\t\n",
       "\t\t\tWHEN job_title like '%data%engineer%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%warehouse%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%architect%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%snowflake%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%etl%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%api%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%cloud%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%aws%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%kafka%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%pipeline%' THEN 'data engineer'\n",
       "\t\t\tWHEN job_title like '%migration%' THEN 'data engineer'\n",
       "\t\t\t\n",
       "\t\t\tWHEN job_title like '%scientist%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%science%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%machine%learning%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '% ai%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%ai %' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%ml%' THEN 'data scientist'\n",
       "\t\t\tWHEN job_title like '%computational%statistics%' then 'data scientist'\n",
       "\t\t\tWHEN job_title like '%quantitative%' then 'data scientist'\n",
       "\t\t\tWHEN job_title like '%artificial%intelligence%' then 'data scientist'\n",
       "\t\t\tEND AS job_standard_name\n",
       "            \n",
       "\tFROM dim_job_info\n",
       "\tORDER BY 2 DESC\n",
       "\t)\n",
       "\n",
       ", filtered_job_details AS (\n",
       "\tSELECT *\n",
       "\tFROM dim_job_details\n",
       "\tWHERE job_id IN (\n",
       "\t\tSELECT job_id FROM enriched \n",
       "-- \t\tWHERE job_standard_name = 'data analyst' )\n",
       "-- \t\tWHERE job_standard_name = 'data engineer' )\n",
       "\t\tWHERE job_standard_name = 'data scientist' )\n",
       ")\n",
       ", filtered_skills AS (\n",
       "\n",
       "\tSELECT job_id, 'SQL' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%sql%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Excel' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%excel%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'PowerBI' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%power%bi%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Tableau' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%tableau%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Python' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%python%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Cloud' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%cloud%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Azure' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%azure%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'AWS' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%aws%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'GCP' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%gcp%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'API' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%api%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Pipeline' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%pipeline%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Dimension Modelling' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%dimension%modelling%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'ETL' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%etl%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'ELT' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%elt%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'DevOps' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%devops%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'CI CD' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%ci%cd%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Spark' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%spark%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Java' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%java%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Scala' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%scala%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Oracle' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%oracle%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Kubernetes' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%kubernetes%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Docker' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%docker%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Apache' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%apache%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Kafka' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%kafka%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Linux' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%linux%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Snowflake' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%snowflake%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Warehouse' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%warehouse%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Modelling' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%modelling%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Visualisation' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%visualisation%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Migration' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%migration%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Management' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%management%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Integration' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%integration%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Platform' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%platform%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Architecture' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%architecture%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Factory' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%factory%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Databricks' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%databricks%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Data Science' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%data%science%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Machine Learning' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%machine%learning%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Computer Science' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%computer%science%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Research' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%research%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Statistic' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%statistic%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Mathematics' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%mathematics%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Quantitative' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%quantitative%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Algorithm' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%algorithm%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Deep Learning' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%deep%learning%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Statistical Analysis' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%statistical%analysis%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Communication Skill' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%communication%skill%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Stakeholder' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%stakeholder%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Reporting' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%reporting%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Agile' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%agile%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Project Management' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%project%management%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Business Intelligence' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%business%intelligence%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Decision Making' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%decision%making%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Interpersonal' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%interpersonal%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Time Management' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%time%management%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Troubleshoot' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%troubleshoot%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'Tertiary Qualification' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%tertiary%qualification%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       "\tUNION\n",
       "\tSELECT job_id, 'PhD' AS skill\n",
       "\t, MIN(line_id) AS line_id\n",
       "\tFROM filtered_job_details\n",
       "\tWHERE detail LIKE '%phd%'\n",
       "\tGROUP BY job_id\n",
       "\n",
       ")\n",
       "SELECT *\n",
       "\t, CASE \n",
       "\t\tWHEN line_id <= 3 THEN '1~3'\n",
       "\t\tWHEN (line_id > 3 AND line_id <= 5) THEN '4~5'\n",
       "\t\tELSE '6+' END AS line_id_category\n",
       "FROM filtered_skills\n",
       "\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for Ranked Line in the Job Description analysis is hidden.\n",
       "<a href=\"javascript:code_toggle()\"></a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @hidden\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    "\n",
    "---\n",
    "\n",
    "```sql\n",
    "\n",
    "WITH \n",
    "enriched AS (\n",
    "\tSELECT job_id, job_title\n",
    "\t\t\t, CASE \n",
    "\t\t\tWHEN job_title LIKE '%data%analyst%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title LIKE '%bi%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title LIKE '%tableau%'  THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%sql%' THEN 'data analyst'\t\t\n",
    "\t\t\tWHEN job_title LIKE '%analytic%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%data%modeller%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%visualisation%'  THEN 'data analyst' \n",
    "\t\t\tWHEN job_title LIKE '%business%intelligence%'  THEN 'data analyst'  \n",
    "\t\t\tWHEN job_title like '%insight%' THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%reporting%' THEN 'data analyst'\n",
    "\t\t\tWHEN job_title like '%model%' THEN 'data analyst'\n",
    "\t\t\t\n",
    "\t\t\tWHEN job_title like '%data%engineer%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%warehouse%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%architect%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%snowflake%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%etl%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%api%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%cloud%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%aws%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%kafka%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%pipeline%' THEN 'data engineer'\n",
    "\t\t\tWHEN job_title like '%migration%' THEN 'data engineer'\n",
    "\t\t\t\n",
    "\t\t\tWHEN job_title like '%scientist%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%science%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%machine%learning%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '% ai%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%ai %' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%ml%' THEN 'data scientist'\n",
    "\t\t\tWHEN job_title like '%computational%statistics%' then 'data scientist'\n",
    "\t\t\tWHEN job_title like '%quantitative%' then 'data scientist'\n",
    "\t\t\tWHEN job_title like '%artificial%intelligence%' then 'data scientist'\n",
    "\t\t\tEND AS job_standard_name\n",
    "            \n",
    "\tFROM dim_job_info\n",
    "\tORDER BY 2 DESC\n",
    "\t)\n",
    "\n",
    ", filtered_job_details AS (\n",
    "\tSELECT *\n",
    "\tFROM dim_job_details\n",
    "\tWHERE job_id IN (\n",
    "\t\tSELECT job_id FROM enriched \n",
    "-- \t\tWHERE job_standard_name = 'data analyst' )\n",
    "-- \t\tWHERE job_standard_name = 'data engineer' )\n",
    "\t\tWHERE job_standard_name = 'data scientist' )\n",
    ")\n",
    ", filtered_skills AS (\n",
    "\n",
    "\tSELECT job_id, 'SQL' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%sql%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Excel' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%excel%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'PowerBI' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%power%bi%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Tableau' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%tableau%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Python' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%python%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Cloud' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%cloud%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Azure' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%azure%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'AWS' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%aws%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'GCP' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%gcp%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'API' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%api%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Pipeline' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%pipeline%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Dimension Modelling' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%dimension%modelling%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'ETL' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%etl%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'ELT' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%elt%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'DevOps' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%devops%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'CI CD' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%ci%cd%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Spark' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%spark%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Java' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%java%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Scala' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%scala%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Oracle' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%oracle%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Kubernetes' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%kubernetes%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Docker' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%docker%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Apache' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%apache%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Kafka' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%kafka%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Linux' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%linux%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Snowflake' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%snowflake%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Warehouse' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%warehouse%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Modelling' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%modelling%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Visualisation' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%visualisation%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Migration' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%migration%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Management' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%management%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Integration' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%integration%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Platform' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%platform%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Architecture' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%architecture%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Factory' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%factory%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Databricks' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%databricks%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Data Science' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%data%science%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Machine Learning' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%machine%learning%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Computer Science' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%computer%science%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Research' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%research%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Statistic' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%statistic%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Mathematics' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%mathematics%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Quantitative' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%quantitative%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Algorithm' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%algorithm%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Deep Learning' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%deep%learning%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Statistical Analysis' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%statistical%analysis%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Communication Skill' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%communication%skill%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Stakeholder' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%stakeholder%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Reporting' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%reporting%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Agile' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%agile%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Project Management' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%project%management%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Business Intelligence' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%business%intelligence%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Decision Making' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%decision%making%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Interpersonal' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%interpersonal%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Time Management' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%time%management%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Troubleshoot' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%troubleshoot%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'Tertiary Qualification' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%tertiary%qualification%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    "\tUNION\n",
    "\tSELECT job_id, 'PhD' AS skill\n",
    "\t, MIN(line_id) AS line_id\n",
    "\tFROM filtered_job_details\n",
    "\tWHERE detail LIKE '%phd%'\n",
    "\tGROUP BY job_id\n",
    "\n",
    ")\n",
    "SELECT *\n",
    "\t, CASE \n",
    "\t\tWHEN line_id <= 3 THEN '1~3'\n",
    "\t\tWHEN (line_id > 3 AND line_id <= 5) THEN '4~5'\n",
    "\t\tELSE '6+' END AS line_id_category\n",
    "FROM filtered_skills\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for Ranked Line in the Job Description analysis is hidden.\n",
    "<a href=\"javascript:code_toggle()\"></a>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
